{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64f58f1b-6779-4eec-b6b6-919e68cd4043",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import os\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e490b7a-90eb-4fd9-a241-e3ca6e36bc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c04e1e87-0849-49cd-be63-4e2a461f6f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load and Combine Stock Data ---\n",
    "def load_stock_data(folder_path):\n",
    "    stock_frames = []\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith('.csv'):\n",
    "            ticker = file.replace('.csv', '').upper()\n",
    "            df_stock = pd.read_csv(os.path.join(folder_path, file), parse_dates=['Date'])\n",
    "            df_stock['Ticker'] = ticker\n",
    "            stock_frames.append(df_stock)\n",
    "    return pd.concat(stock_frames, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "417395c6-b07f-42ae-9e63-636b7080f268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Sentiment Analysis Function ---\n",
    "def sentiment_analysis(df):\n",
    "    print(\"\\n=== Sentiment Analysis ===\")\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    df['sentiment_scores'] = df['headline'].apply(lambda x: sia.polarity_scores(x))\n",
    "    df['sentiment_compound'] = df['sentiment_scores'].apply(lambda x: x['compound'])\n",
    "    df['sentiment_label'] = df['sentiment_compound'].apply(\n",
    "        lambda x: 'positive' if x > 0.05 else ('negative' if x < -0.05 else 'neutral')\n",
    "    )\n",
    "    print(df[['headline', 'sentiment_compound', 'sentiment_label']].head())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3369efb2-6a3c-4250-bb79-670f317df409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Correlation Analysis Function ---\n",
    "\n",
    "def correlation_analysis(merged_df):\n",
    "    print(\"\\n=== Correlation Analysis ===\")\n",
    "    \n",
    "    # Ensure date columns are datetime.date\n",
    "    merged_df['date'] = pd.to_datetime(merged_df['date']).dt.date\n",
    "    \n",
    "    # Aggregate daily sentiment by mean compound score for each stock\n",
    "    daily_sentiment = merged_df.groupby(['date', 'stock'])['sentiment_compound'].mean().reset_index()\n",
    "    \n",
    "    # Aggregate daily stock closing price (mean in case multiple entries per day)\n",
    "    daily_price = merged_df.groupby(['date', 'stock'])['Close'].mean().reset_index()\n",
    "    \n",
    "    # Merge sentiment and price on date and stock\n",
    "    combined = pd.merge(daily_sentiment, daily_price, on=['date', 'stock'], how='inner')\n",
    "    \n",
    "    # Calculate correlation per stock\n",
    "    stocks = combined['stock'].unique()\n",
    "    for ticker in stocks:\n",
    "        df_stock = combined[combined['stock'] == ticker]\n",
    "        corr = df_stock['sentiment_compound'].corr(df_stock['Close'])\n",
    "        print(f\"Correlation between sentiment and close price for {ticker}: {corr:.4f}\")\n",
    "        \n",
    "        # Plotting\n",
    "        fig, ax1 = plt.subplots(figsize=(10,5))\n",
    "        ax2 = ax1.twinx()\n",
    "        \n",
    "        ax1.plot(df_stock['date'], df_stock['sentiment_compound'], 'g-', label='Avg Daily Sentiment')\n",
    "        ax2.plot(df_stock['date'], df_stock['Close'], 'b-', label='Avg Close Price')\n",
    "        \n",
    "        ax1.set_xlabel('Date')\n",
    "        ax1.set_ylabel('Sentiment', color='g')\n",
    "        ax2.set_ylabel('Close Price', color='b')\n",
    "        plt.title(f'Daily Sentiment vs. Stock Price for {ticker}')\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cd29ed-d761-45d6-88ad-785cdd79183c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# --- Main Function ---\n",
    "def main():\n",
    "    # Load news data\n",
    "    df = pd.read_csv('../data/raw_analyst_ratings.csv')\n",
    "    df.columns = df.columns.str.strip().str.lower()\n",
    "\n",
    "    if 'date' not in df.columns or 'headline' not in df.columns or 'stock' not in df.columns:\n",
    "        print(\"âŒ Required columns 'date', 'headline', or 'stock' not found.\")\n",
    "        return\n",
    "\n",
    "    df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "    df = df.dropna(subset=['date'])\n",
    "\n",
    "    \n",
    "\n",
    "    # Feature Engineering\n",
    "    df['headline_length'] = df['headline'].apply(lambda x: len(str(x).split()))\n",
    "    df['publication_day'] = df['date'].dt.day_name()\n",
    "    df['publication_hour'] = df['date'].dt.hour\n",
    "    df['stock'] = df['stock'].str.upper()\n",
    "\n",
    "    # Load pre-downloaded stock data\n",
    "    stock_data = load_stock_data('../data/yfinance_data/')  # directory with multiple stock CSVs\n",
    "    stock_data.rename(columns={'Date': 'date'}, inplace=True)\n",
    "    stock_data['Ticker'] = stock_data['Ticker'].str.upper()\n",
    "    df['date'] = df['date'].dt.tz_localize(None)\n",
    "    stock_data['date'] = stock_data['date'].dt.tz_localize(None)\n",
    "\n",
    "\n",
    "    # Merge on date and ticker\n",
    "    merged_df = pd.merge(df, stock_data, left_on=['date', 'stock'], right_on=['date', 'Ticker'], how='left')\n",
    "\n",
    "    # Apply sentiment\n",
    "    merged = sentiment_analysis(merged_df)\n",
    "\n",
    "    # Run all analysis\n",
    "    #descriptive_stats(merged)\n",
    "    #topic_modeling(merged)\n",
    "    #publisher_analysis(merged)\n",
    "    correlation_analysis(merged_df)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe90cd00-46c2-4431-9217-16df1ec625fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a425fc-1ffb-4011-90d9-5856cfe463a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6938181e-22a2-4495-8a79-77d31c0b8a71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfa080c-70bb-4bf2-a357-c16bda1ab2e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
